{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c77b50",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/danski3456/coding_exercises/blob/main/Demand%20Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9d6ef",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The objective of this notebook, is to learn how to transform a time-series problem (demand forecasting) into a tabular one.\n",
    "\n",
    "For this we will use the M5 competition dataset, large and popular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db40d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nv https://raw.githubusercontent.com/danski3456/notebook_grading/main/utils.py -O utils.py\n",
    "%run utils.py\n",
    "\n",
    "!pip install eccd_datasets > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2434c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_NAME = \"Nombre Apellido\"\n",
    "COURSE_NAME = \"eccd-feb22\"\n",
    "EXERCISE_NAME = \"demand-forecsting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f15326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "from eccd_datasets import load_m5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8ba09",
   "metadata": {},
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "Since the dataset is quite large, it comes in three pieces: calendar events, sales and sell_prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_m5()\n",
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = datasets[\"calendar\"]\n",
    "df_calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f52111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = datasets[\"sales\"]\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbacf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = datasets[\"sell_prices\"]\n",
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_id(id_: str, sales: pd.DataFrame, prices: pd.DataFrame, calendar: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts the dataframe associated with a single item id in long format.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = sales[sales[\"id\"] == id_].drop(columns=[\"id\"])\n",
    "    df = pd.melt(\n",
    "        df, \n",
    "        id_vars=[\n",
    "            \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    "        var_name = \"d\",\n",
    "        value_name = \"units_sold\"\n",
    "        \n",
    "    )\n",
    "    \n",
    "    df = df.merge(calendar, on=\"d\", how=\"left\") \n",
    "    df = df.merge(prices, on=[\"item_id\", \"store_id\", \"wm_yr_wk\"], how=\"left\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = \"HOBBIES_1_001_CA_1_validation\"\n",
    "df_id = get_data_from_id(ID, df_sales, df_prices, df_calendar)\n",
    "print(df_id.shape)\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "ax.plot(df_id[\"units_sold\"])\n",
    "ax.set_xlabel(\"Days\")\n",
    "ax.set_ylabel(\"# Units sold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a87bf",
   "metadata": {},
   "source": [
    "We can drop all the attributes that describe the price but don't change across rows since they will not provide useful informaton for training a model.\n",
    "\n",
    "Furthermore, there are many attributes that are redundant and can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a14de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_id.drop(columns=[\n",
    "    \"item_id\", \"dept_id\", \"state_id\", \"cat_id\", \"store_id\", \"d\", \"wm_yr_wk\",\n",
    "    \"weekday\", \"month\", \"year\", \"wday\"\n",
    "])\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca9947",
   "metadata": {},
   "source": [
    "We observe that for some events we don't have a price. We can assume that in those cases, the price is equal to the oldest price available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id[\"sell_price\"] = df_id[\"sell_price\"].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_temporal_features(date_variable: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes `date_variable` which should be a pandas datetype\n",
    "    and creates several temporal features from it.\n",
    "    \n",
    "    In particular, it should create the additional columns in the dataframe\n",
    "    \n",
    "    Asume that all variables are in the range [0, x])\n",
    "    \n",
    "    `day_of_month`\n",
    "    `month`\n",
    "    `day_of_week`\n",
    "    `day_of_week_sin` \n",
    "    `day_of_week_cos`\n",
    "    `month_cos`\n",
    "    `month_sin`\n",
    "    `day_of_month_sin`\n",
    "    `day_of_month_cos`\n",
    "    `lag_1`\n",
    "    `lag_7`\n",
    "    \n",
    "    Remember to sort the dataframe using the data varaible with the most\n",
    "    recent values in the bottom.\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    # Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = build_temporal_features(\"date\", df_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afdf02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[1020]\n",
    "assert np.allclose(row[\"day_of_week\"], 3)\n",
    "assert np.allclose(row[\"day_of_month\"], 14)\n",
    "assert np.allclose(row[\"month_sin\"], -0.866025)\n",
    "assert np.allclose(row[\"month_cos\"], 0.5)\n",
    "assert np.allclose(row[\"day_of_week_sin\"], 0.974928)\n",
    "assert np.allclose(row[\"day_of_week_cos\"], -0.222521)\n",
    "assert np.allclose(row[\"day_of_month_cos\"], -0.874347)\n",
    "assert np.allclose(row[\"lag_1\"], 1)\n",
    "assert np.allclose(row[\"lag_2\"], 1)\n",
    "assert np.allclose(row[\"lag_14\"], 0)\n",
    "\n",
    "answer_month = row[\"month\"]\n",
    "answer_month_sin = row[\"day_of_month_sin\"]\n",
    "answer_lag7 = row[\"lag_7\"]\n",
    "\n",
    "print(answer_month)\n",
    "print(answer_month_sin)\n",
    "print(answer_lag7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ccc1bb",
   "metadata": {},
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "Unlike normal problems with tabular data, we can't randomly split the data (since each row has a temporal component).\n",
    "\n",
    "For this we will manually split the dataset and keep the last 30 as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop(\"units_sold\")\n",
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X.iloc[:-30], y.iloc[:-30]\n",
    "X_test, y_test = X.iloc[-30:], y.iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a24d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c25b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55058cd9",
   "metadata": {},
   "source": [
    "# Training with a simple AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = ARIMA(y_train, order=(7, 1, 0))\n",
    "arima_res = arima.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = arima_res.forecast(steps=30)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab039995",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_pred, y_test.values, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbbdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_pred, label=\"predicted\")\n",
    "ax.plot(y_test.values, label=\"original\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a091f45",
   "metadata": {},
   "source": [
    "# Training using ML with Tabular Data\n",
    "\n",
    "For simplicity we are going to use only the numerical features, without trying to properly encode the other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca16c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 450,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed': 200,\n",
    "    'num_threads': 1\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "model.fit(X_train.select_dtypes(include=[\"float\", \"int\"]), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test.select_dtypes(include=[\"float\", \"int\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d02389",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_pred, y_test.values, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ab8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_pred, label=\"predicted\", marker=\"*\")\n",
    "ax.plot(y_test.values, label=\"original\", marker=\"o\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0fdee",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We showed how we can build a tabular dataset from a time-series and how we can use traditional techniques such as `Regression Trees` to train such model.\n",
    "\n",
    "In this example our analysis was quite basic and we kept only a minium number of variables.\n",
    "\n",
    "Furthermore, an approach that was not explored is to train several items at the same (which requires more computing power), which can further incrase the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41045c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6097bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proposed_solution = {\n",
    "'attempt': {\n",
    "    'course_name': COURSE_NAME,\n",
    "    'exercise_name': EXERCISE_NAME,\n",
    "    'username': STUDENT_NAME,\n",
    "},\n",
    "'task_attempts': [\n",
    "\t{\n",
    "\t\t\"name\": \"Month\",\n",
    "\t\t\"answer\": str(answer_month),\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"name\": \"Month Sin\",\n",
    "\t\t\"answer\": str(answer_month_sin),\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"name\": \"7th Lag\",\n",
    "\t\t\"answer\": str(answer_lag7),\n",
    "\t},\n",
    "]\n",
    "\n",
    "\n",
    "}\n",
    "check_solution(proposed_solution)\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
