{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b116f02",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/danski3456/coding_exercises/blob/main/exercises/Pricing%20Recommendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nv https://raw.githubusercontent.com/danski3456/notebook_grading/main/utils.py -O utils.py\n",
    "%run utils.py\n",
    "!pip install eccd_datasets > /dev/nul\n",
    "!pip install category_encoders > /dev/nul\n",
    "!pip install shap > /dev/nul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19adde80",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_NAME = \"Nombre Apellido\"\n",
    "\n",
    "COURSE_NAME = \"eccd-feb22\"\n",
    "EXERCISE_NAME = \"price-recommendation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319fad0",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Explore how a pricing automation / recommendation project looks like. \n",
    "\n",
    "In a pricing recommendation problem, often the most accurate prediction is not necessary the most important goal.\n",
    "Indeed, sometimes offering a range of possible values or an explanation on how a certain variable affects the outcomes can be more useful for an end-user.\n",
    "\n",
    "We will use a very basic data cleaning of a popular dataset before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31073132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from eccd_datasets import load_mercari\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13902e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_mercari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3774c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aabcd7",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this excercise we are going to ignore both `name` and `item_description` categories.\n",
    "\n",
    "For the `category_name` feature, we are going to split it in three. \n",
    "\n",
    "Then, we are going to use a categorical encoder to encode all string atributes into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cat_1\"], df[\"cat_2\"], df[\"cat_3\"] = zip(*df[\"category_name\"].apply(split_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c00283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    \"item_condition_id\", \"brand_name\", \"shipping\", \"cat_1\", \"cat_2\", \"cat_3\", \"price\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4219c",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "As always, we divide our dataset into a training and test datasets.\n",
    "\n",
    "We fix the `random_seed` to make sure that our experiment is reproducible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop(\"price\")\n",
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe8e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0021be63",
   "metadata": {},
   "source": [
    "## Target Encoder\n",
    "\n",
    "We will proceed to build a target encoder for the columns that still have strings in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target_encoder(X: pd.DataFrame, y: pd.DataFrame) -> TargetEncoder:\n",
    "    \"\"\"\n",
    "    Train a target encoder on columns \"brand_name, \"cat_1\", \"cat_2\", \"cat_3\"\n",
    "    using the train dataset and return the \"fitted\" encoder.\n",
    "    \"\"\"\n",
    "    # Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = build_target_encoder(X_train, y_train)\n",
    "\n",
    "row1 = X_train.iloc[:1]\n",
    "row1_t = te.transform(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3104140",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(row1_t[\"cat_1\"], y_train.loc[X_train[\"cat_1\"] == row1[\"cat_1\"].iloc[0]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4311cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "row2 = X_test.iloc[:1]\n",
    "row2_t = te.transform(row2)\n",
    "answer_target_encoder = row2_t[\"cat_2\"].values[0]\n",
    "print(\"cat_2 target encoder\", answer_target_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae1441",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "For training we are going to use a very popular machine learning model named `LightGBM` from Micrsoft.\n",
    "\n",
    "One of the advantages of this model is that it includes a `quantile loss` that we can use to obtain intervals.\n",
    "\n",
    "We will train the models three times, one for each quantile: `10%, 50% (the median) and 90%`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbe147",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = te.transform(X_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    'metric': 'quantile',\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 15,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed': 42,\n",
    "    'num_threads': 1\n",
    "}\n",
    "\n",
    "quantiles = [.1, .5, .9]\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i in range(len(quantiles)):\n",
    "    \n",
    "    reg = lgb.LGBMRegressor(alpha=quantiles[i], **params)\n",
    "    \n",
    "    model = reg.fit(X_train_t, y_train)\n",
    "    \n",
    "    X_test_t = te.transform(X_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test_t)\n",
    "    \n",
    "    preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f884202",
   "metadata": {},
   "source": [
    "Here we process the three predicitions, one for each model and use them to build the corresponding intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078927d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(preds).T\n",
    "df_preds[\"y_test\"] = y_test.values\n",
    "df_preds.columns = [\"q10\", \"q50\", \"q90\", \"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed6bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_within_interval(df_preds: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Implement a function that counts for how many\n",
    "    rows it holds that the true value $y \\in [q10, q90]$\n",
    "    \n",
    "    For example, if in a row the real value of the target variable is 10,\n",
    "    q10 is 5 and q90 is 15, that row counts.\n",
    "    If in a different row, the target variable is 20, q10 is 5 and q90 is 15,\n",
    "    that row does not count.\n",
    "    \"\"\"\n",
    "    # Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b810caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_interval =  get_result_within_interval(df_preds)\n",
    "print(\"Results within interval\", answer_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a5469e",
   "metadata": {},
   "source": [
    "# Shapely value\n",
    "\n",
    "Finally, we can use the shapley value to obtain an explanation of how each feature contributes to the final prediction.\n",
    "\n",
    "In a price recommendatino problem this information is very helpful to end-users, possibly even more than the actual price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faac4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cbf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a3315f",
   "metadata": {},
   "source": [
    "We can also use the Shapley value to predict a single element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3942ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_t.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c1452",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proposed_solution = {\n",
    "'attempt': {\n",
    "    'course_name': COURSE_NAME,\n",
    "    'exercise_name': EXERCISE_NAME,\n",
    "    'username': STUDENT_NAME,\n",
    "},\n",
    "'task_attempts': [\n",
    "\t{\n",
    "\t\t\"name\": \"target-encoder\",\n",
    "\t\t\"answer\": answer_target_encoder,\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"name\": \"results-within-interval\",\n",
    "\t\t\"answer\": answer_interval,\n",
    "\t},\n",
    "]\n",
    "\n",
    "}\n",
    "check_solution(proposed_solution)\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
